{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678ba6e8-acce-4f47-9564-4ff088ab7a37",
   "metadata": {},
   "source": [
    "# 1) What is the purpose of the artificial intelligence for our problem?\n",
    "\n",
    "The artificial intelligence will classify images of 10 real-life objects.\n",
    "It will be trained on 50,000 images from the *CIFAR-10* dataset. These images are 32x32 pixels and contain an RGB channel, meaning they have dimensions of 3x32x32.\n",
    "\n",
    "Therefore, we are going to build a classifier. To do this, we'll need to use the **softmax** function, as there are 10 possible classes. \n",
    "\n",
    "# 2) Collecting and preparing the data\n",
    "\n",
    "The *CIFAR10* dataset is provided by PyTorch through the `torchvision` module. It returns a complete dataset for either the training set or the validation set. However, we need to create the list of class names.\\\n",
    "\n",
    "As mentioned earlier, the dataset consists of PIL images, which means we'll need to convert these images into tensors. We may want to crop or flip the images to augment the training data for the model. Finally, normalizing the images will help the neurons learn faster, as some activation functions perform better with inputs in a smaller range. In our case, the PIL images are 8-bit, meaning their values range between 0 and 255. However, these values are scaled to the range [0, 1] after being converted into tensors. Because the images have three color channels, we should still normalize them to reduce potential biases between the channels.\n",
    "\n",
    "# 3) Model selection\n",
    "\n",
    "Now that we understand our problem and have collected and prepared our data, we can focus on selecting a model. There are many possible architectures to choose from, but Convolutional Neural Networks (**CNNs**) are typically the most effective for image-related tasks. We can either use existing pretrained models, such as *ResNet* or *VGG*, and fine-tune them for our specific problem, or experiment with different models ourselves.\n",
    "\n",
    "To start, we'll use the pretrained model ResNet to get an initial sense of how well the model performs. Afterward, we'll develop our own custom model based on what we learn from this initial approach. \n",
    "\n",
    "# 4) Training and validation loop\n",
    "\n",
    "Once we have our model, the next step is obviously to train it. For this, we'll use the two datasets created earlier with the `torchvision` module. It's important to loop over a **dataloader**, and not directly over the **dataset**. The dataloader requires the `batch_size` argument, which will be set to 64 by default. We'll also need an optimizer. There are many options, but starting with **SGD** and **Adam** should be sufficient for our purpose.\n",
    "\n",
    "The validation loop ensures that our model isn't *overfitting*. Since the model is not trained on data from the validation set, we can compare the results between the training and validation sets at the end of the process. We'll use several metrics to evaluate the model's performance, such as **accuracy**, the **confusion matrix**, **recall**, and **precision**.\n",
    "\n",
    "# 5) Saving and loading the model\n",
    "Once we are satisfied with the results, the next step is to save the model. In practice, we'll save the model's weights and biases. To reload it, we'll need to recreate the model object and load the saved parameters into it.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
